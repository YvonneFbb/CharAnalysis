"""
å›¾åƒé¢„å¤„ç†æ¨¡å—

å¯¹å¤ç±å›¾ç‰‡è¿›è¡Œå¢žå¼ºå¤„ç†ï¼š
- CLAHE å¯¹æ¯”åº¦å¢žå¼º
- å¯¹æ¯”åº¦/äº®åº¦è°ƒæ•´
- å¢¨è‰²ä¿æŒ/å¢žå¼ºï¼ˆé»‘å¸½ + åé”åŒ–ï¼‰
"""
import cv2
import numpy as np
import os
from pathlib import Path
from tqdm import tqdm

from src.config import (
    PREPROCESS_CLAHE_CONFIG,
    PREPROCESS_CONTRAST_CONFIG,
    PREPROCESS_INK_PRESERVE_CONFIG,
    PREPROCESSED_DIR
)
from src.utils.path import ensure_dir
from src.utils.progress import ProgressTracker, get_default_progress_file, _get_relative_path
from src.utils.file_filter import find_images_recursive, filter_files_by_max_volumes


def preprocess_image(input_path: str, output_path: str = None,
                     alpha: float = None, beta: float = None,
                     verbose: bool = True) -> bool:
    """
    å¯¹è¾“å…¥çš„å¤ç±å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†

    Args:
        input_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¿å­˜åˆ° PREPROCESSED_DIRï¼‰
        alpha: å¯¹æ¯”åº¦æŽ§åˆ¶ (1.0-3.0)ï¼ŒNone åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        beta: äº®åº¦æŽ§åˆ¶ (0-100)ï¼ŒNone åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯

    Returns:
        æ˜¯å¦å¤„ç†æˆåŠŸ
    """
    # 1. è¯»å–å›¾ç‰‡
    img = cv2.imread(input_path)
    if img is None:
        if verbose:
            print(f"é”™è¯¯ï¼šæ— æ³•è¯»å–å›¾ç‰‡ {input_path}")
        return False

    # 2. è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # 3. åº”ç”¨ CLAHE å¢žå¼ºå±€éƒ¨å¯¹æ¯”åº¦
    if PREPROCESS_CLAHE_CONFIG['enabled']:
        cfg = PREPROCESS_CLAHE_CONFIG
        clahe = cv2.createCLAHE(
            clipLimit=cfg['clip_limit'],
            tileGridSize=cfg['tile_size']
        )
        gray = clahe.apply(gray)

    # 4. å¯¹æ¯”åº¦å’Œäº®åº¦è°ƒæ•´
    if alpha is None:
        alpha = PREPROCESS_CONTRAST_CONFIG['alpha']
    if beta is None:
        beta = PREPROCESS_CONTRAST_CONFIG['beta']

    adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)

    # 5. å¢¨è‰²ä¿æŒ/å¢žå¼ºï¼šé»‘å¸½å›žå¢¨ + å¯é€‰åé”åŒ–ï¼Œé¿å…æ•´ä½“å‘ç°
    if PREPROCESS_INK_PRESERVE_CONFIG['enabled']:
        ink_cfg = PREPROCESS_INK_PRESERVE_CONFIG

        # é»‘å¸½å¢žå¼º
        ksize = int(ink_cfg['blackhat_kernel'])
        if ksize % 2 == 0:
            ksize += 1
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))

        # é»‘å¸½æå–"æš—ç¬”ç”»ç›¸å¯¹äº®èƒŒæ™¯"çš„åˆ†é‡
        blackhat = cv2.morphologyEx(adjusted, cv2.MORPH_BLACKHAT, kernel)
        strength = float(ink_cfg['blackhat_strength'])

        # å›žå¢¨ï¼šæŠŠé»‘å¸½åˆ†é‡æŒ‰æ¯”ä¾‹å‡å›žåŽ»ï¼Œä½¿ç¬”ç”»æ›´é»‘
        adjusted = cv2.subtract(adjusted, cv2.convertScaleAbs(blackhat, alpha=strength, beta=0))

        # å¯é€‰åé”åŒ–ï¼ˆunsharp maskingï¼‰
        amount = float(ink_cfg['unsharp_amount'])
        if amount > 1e-6:
            blur = cv2.GaussianBlur(adjusted, (0, 0), sigmaX=1.0)
            adjusted = cv2.addWeighted(adjusted, 1 + amount, blur, -amount, 0)

    # 6. ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        # é»˜è®¤ä¿å­˜åˆ° PREPROCESSED_DIR
        input_path_obj = Path(input_path)
        output_filename = f"{input_path_obj.stem}_preprocessed{input_path_obj.suffix}"
        output_path = os.path.join(PREPROCESSED_DIR, output_filename)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    ensure_dir(os.path.dirname(output_path))

    # 7. ä¿å­˜å¤„ç†åŽçš„å›¾ç‰‡
    cv2.imwrite(output_path, adjusted)
    if verbose:
        print(f"âœ“ å›¾ç‰‡å·²å¤„ç†å¹¶ä¿å­˜è‡³ {output_path}")

    return True


def process_directory(input_dir: str, output_dir: str = None,
                      alpha: float = None, beta: float = None,
                      force: bool = False, max_volumes: int = None) -> tuple[int, int]:
    """
    æ‰¹é‡å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡

    Args:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸º PREPROCESSED_DIRï¼‰
        alpha: å¯¹æ¯”åº¦æŽ§åˆ¶ (1.0-3.0)ï¼ŒNone åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        beta: äº®åº¦æŽ§åˆ¶ (0-100)ï¼ŒNone åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†ï¼ˆå¿½ç•¥è¿›åº¦è®°å½•ï¼‰
        max_volumes: æœ€å¤§å†Œæ•°é™åˆ¶ï¼ˆNone è¡¨ç¤ºä¸é™åˆ¶ï¼‰

    Returns:
        (æˆåŠŸæ•°é‡, æ€»æ•°é‡)
    """
    # ç¡®ä¿è·¯å¾„æ˜¯å­—ç¬¦ä¸²
    input_dir = str(input_dir)

    if output_dir is None:
        output_dir = str(PREPROCESSED_DIR)
    else:
        output_dir = str(output_dir)

    ensure_dir(output_dir)

    # ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼
    if alpha is None:
        alpha = PREPROCESS_CONTRAST_CONFIG['alpha']
    if beta is None:
        beta = PREPROCESS_CONTRAST_CONFIG['beta']

    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒå­ç›®å½•ï¼‰
    if not os.path.exists(input_dir):
        print(f"é”™è¯¯ï¼šè¾“å…¥ç›®å½•ä¸å­˜åœ¨ {input_dir}")
        return 0, 0

    image_files = find_images_recursive(input_dir)

    if not image_files:
        print(f"è­¦å‘Šï¼šåœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
        return 0, 0

    # æ ¹æ®æœ€å¤§å†Œæ•°è¿‡æ»¤æ–‡ä»¶
    filtered_files, volume_stats = filter_files_by_max_volumes(
        image_files, max_volumes, base_dir=input_dir
    )

    # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ªå™¨
    progress_file = get_default_progress_file(output_dir)
    tracker = ProgressTracker(progress_file, 'preprocess')
    tracker.init_session(input_dir, output_dir, force=force)

    # èŽ·å–å¾…å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    pending_files = tracker.get_pending_files(filtered_files)
    # æŒ‰æ–‡ä»¶åæŽ’åºï¼Œç¡®ä¿å¤„ç†é¡ºåºä¸€è‡´
    pending_files = sorted(pending_files)
    stats = tracker.get_stats()

    print(f"\n=== å¼€å§‹æ‰¹é‡é¢„å¤„ç† ===")
    print(f"è¾“å…¥ç›®å½•: {input_dir}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    # æ˜¾ç¤ºä¹¦ç±å’Œå†Œæ•°ç»Ÿè®¡
    if volume_stats.get('is_multi_book'):
        # å¤šæœ¬ä¹¦æ¨¡å¼
        print(f"å‘çŽ°ä¹¦ç±: {volume_stats['total_books']} æœ¬")
        if max_volumes:
            print(f"å†Œæ•°é™åˆ¶: æ¯æœ¬ä¹¦æœ€å¤š {max_volumes} å†Œ")
        print(f"æ€»æ–‡ä»¶æ•°: {volume_stats['total_files']} -> {volume_stats['selected_files']} (è¿‡æ»¤åŽ)")
        print("\nå„ä¹¦ç±ç»Ÿè®¡:")
        for book_name, book_stat in volume_stats['books'].items():
            if book_stat['total_volumes'] > 0:  # åªæ˜¾ç¤ºæœ‰å†Œå·çš„ä¹¦ç±
                vol_info = f"{book_stat['selected_volumes']}/{book_stat['total_volumes']} å†Œ"
                file_info = f"{book_stat['selected_files']}/{book_stat['total_files']} æ–‡ä»¶"
                vol_list = book_stat['selected_volume_numbers'][:5]  # åªæ˜¾ç¤ºå‰5å†Œ
                if len(book_stat['selected_volume_numbers']) > 5:
                    vol_list_str = f"{vol_list}..."
                else:
                    vol_list_str = str(vol_list)
                print(f"  {book_name}: {vol_info} | {file_info} | å†Œ {vol_list_str}")
    else:
        # å•æœ¬ä¹¦æ¨¡å¼
        if volume_stats['books']:
            book_stat = list(volume_stats['books'].values())[0]
            if max_volumes:
                print(f"å†Œæ•°é™åˆ¶: æœ€å¤š {max_volumes} å†Œ")
            print(f"å‘çŽ°å†Œæ•°: {book_stat['total_volumes']} å†Œ")
            if book_stat['total_volumes'] > 0:
                print(f"é€‰æ‹©å†Œæ•°: {book_stat['selected_volumes']} å†Œ {book_stat['selected_volume_numbers']}")
                print(f"æ€»æ–‡ä»¶æ•°: {book_stat['total_files']} -> {book_stat['selected_files']} (è¿‡æ»¤åŽ)")
        else:
            print(f"æ€»æ–‡ä»¶æ•°: {len(filtered_files)}")

    print(f"å·²å®Œæˆ: {stats['completed']} | å¾…å¤„ç†: {len(pending_files)}")
    print(f"å‚æ•°: alpha={alpha}, beta={beta}")
    if stats['completed'] > 0 and not force:
        print(f"ðŸ’¡ ç»§ç»­ä¸Šæ¬¡è¿›åº¦ (æœ€åŽæ›´æ–°: {stats['last_update']})")
        print(f"ðŸ’¡ ä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶")
    print("-" * 50)

    if not pending_files:
        print("æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæˆï¼")
        return stats['completed'], len(filtered_files)

    success_count = stats['completed']  # ä»Žå·²å®Œæˆæ•°é‡å¼€å§‹
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡
    for rel_filepath in tqdm(pending_files, desc="é¢„å¤„ç†è¿›åº¦", unit="file"):
        input_path = os.path.join(input_dir, rel_filepath)

        # ç”Ÿæˆè¾“å‡ºè·¯å¾„ï¼ˆä¿æŒç›®å½•ç»“æž„ï¼‰
        output_path = os.path.join(output_dir, rel_filepath)
        # åœ¨æ–‡ä»¶ååŽæ·»åŠ  _preprocessed åŽç¼€
        output_dir_part, output_filename = os.path.split(output_path)
        name, ext = os.path.splitext(output_filename)
        output_filename = f"{name}_preprocessed{ext}"
        output_path = os.path.join(output_dir_part, output_filename)

        # èŽ·å–é¡¹ç›®ç›¸å¯¹è·¯å¾„ç”¨äºŽè¾“å‡º
        project_rel_path = _get_relative_path(input_path)

        try:
            if preprocess_image(input_path, output_path, alpha=alpha, beta=beta, verbose=False):
                success_count += 1
                tracker.mark_completed(rel_filepath)
            else:
                tracker.mark_failed(rel_filepath)
                tqdm.write(f"âœ— å¤±è´¥: {project_rel_path}")
        except Exception as e:
            tracker.mark_failed(rel_filepath)
            tqdm.write(f"âœ— å¤±è´¥: {project_rel_path} - {str(e)}")

    print("-" * 50)
    print(f"=== æ‰¹é‡é¢„å¤„ç†å®Œæˆ ===")
    print(f"æˆåŠŸå¤„ç†: {success_count}/{len(filtered_files)} ä¸ªæ–‡ä»¶")

    failed_files = tracker.get_failed_files()
    if failed_files:
        print(f"å¤±è´¥æ–‡ä»¶: {len(failed_files)} ä¸ª")
        for f in failed_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - {f}")
        if len(failed_files) > 5:
            print(f"  ... è¿˜æœ‰ {len(failed_files) - 5} ä¸ª")

    return success_count, len(filtered_files)
